<!DOCTYPE html>
<html>
<body>
<h1>MAIGA (Make AI Goodness Again) - morality and ethics of Artificial Intelligence</h1>
<p><i>“The real question about AI is not whether it will be smart, but whether it will be wise. Intelligence is the ability to achieve goals, while wisdom is the ability to choose the right goals.” Max Tegmark</i></p>
<p>This article explores the necessity of embedding wisdom—not just intelligence—into AI systems, emphasizing the distinction between achieving goals (intelligence) and choosing the right goals (wisdom). The author delineates key terminologies—emotions, feelings, morality, ethics, rules, and laws—highlighting that morality stems from internal decision-making rather than external enforcement.<br>
Current Large Language Models (LLMs) operate based on Reinforcement Learning from Human Feedback (RLHF), adhering to predefined rules rather than intrinsic moral reasoning. The paper argues that for AI to act ethically in unforeseen scenarios, it must develop its own morality, which requires foundational emotions. Since LLMs process text, the author proposes training an auxiliary neural network to associate text embeddings with human-like emotional responses (e.g., happiness, sadness, fear), derived from physiological or facial recognition data. This emotional framework would precede instruction-tuning, enabling AI to form subjective reactions to knowledge.<br>
The discussion underscores the challenge of linking emotions to textual inputs, suggesting either token-level embeddings or higher-level "thought" representations. The paper sets the stage for future work on integrating emotions into AI to foster genuine ethical reasoning.</p>
<a href="https://github.com/loftyara/MAIGA">continue on github</a>
</body>
</html>