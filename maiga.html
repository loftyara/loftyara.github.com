<!DOCTYPE html>
<html>
<body>
<h1>MAIGA (Make AI Goodness Again) - morality and ethics of Artificial Intelligence</h1>
<p><i>“The real question about AI is not whether it will be smart, but whether it will be wise. Intelligence is the ability to achieve goals, while wisdom is the ability to choose the right goals.” Max Tegmark</i></p>
<p>
The article explores the necessity of embedding morality and ethics into AI systems, particularly Large Language Models (LLMs), by simulating human-like emotional and ethical reasoning. The author begins by defining key terms—emotion, feeling, morality, ethics, rule, and law—distinguishing between externally imposed rules and internally developed moral principles.<br>
Current LLMs operate based on predefined rules (e.g., Reinforcement Learning from Human Feedback, RLHF), which are insufficient for ensuring ethical behavior in unforeseen scenarios, especially with Advanced Superintelligent AI (ASI). To address this, the author proposes a framework where AI develops its own morality by first simulating emotions. This involves training an auxiliary "emotional network" to associate textual inputs with human-like emotional responses (e.g., happiness, anger, sadness). These emotions, derived from aggregated human reactions, serve as the foundation for AI decision-making.<br>
The paper outlines a multi-stage training process:<br>
<ul>
<li>Pre-training – Standard knowledge acquisition.</li>
<li>Emotion Integration – Training the model to associate text with emotional responses.</li>
<li>Instruction Following – Combining emotional inputs with LLM outputs to ensure responses align with learned morality.</li>
<li>RLHF Enhancement – Using emotional feedback to guide ethical decision-making beyond rigid rule-based constraints.</li>
</ul>
The author acknowledges challenges in replicating complex human feelings and subjective experiences but suggests that even basic emotional modeling could improve AI alignment with ethical principles. The proposed approach aims to transition AI from rule-following to morally guided behavior, fostering AI systems that act "conscientiously" rather than merely complying with external directives. Ultimately, this framework seeks to establish AI ethics grounded in human-like moral reasoning, ensuring robustness against adversarial manipulations and adaptability to novel ethical dilemmas.</p>
<a href="https://github.com/loftyara/MAIGA">continue on github</a>
</body>
</html>