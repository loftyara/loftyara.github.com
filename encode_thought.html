<!DOCTYPE html>
<html>
<body>
<h1>Encode the thought - LLM training for understanding meaning instead of predicting tokens</h1>
<p><i>“Thoughts die the moment they are embodied by words.” A. Schopenhauer</i></p>
<p>Current large language models (LLMs) excel at predicting tokens and generating coherent text but often fall short in understanding the deeper meaning behind the words. This paper critiques the token-centric training paradigm of LLMs, arguing that it prioritizes syntax over semantics, leading to models that mimic language without truly comprehending it. Drawing a distinction between words and thoughts, we propose that thoughts are best captured at the level of sentences or larger text fragments, rather than individual tokens. To address this limitation, we explore two alternative training approaches: (1) Whole Sentence Prediction, where models predict entire sentences or paragraphs to encourage a focus on meaning, and (2) Bottleneck Encoder, where an encoder-decoder architecture compresses text into semantic embeddings, forcing the model to encode the underlying thought. While these approaches present computational and scalability challenges, they offer a promising direction for developing LLMs that move beyond statistical parroting to achieve true understanding. This work invites a reimagining of LLM training paradigms, emphasizing the encoding of meaning over the prediction of tokens. This approach aims to create models that understand, rather than memorize, information, while reducing resource consumption. The method remains theoretical and requires experimental validation, but it offers a promising alternative to conventional LLM training, with potential benefits in efficiency, control, and model interpretability.</p>
<a href="https://github.com/loftyara/Encode_thought">continue on github</a>
</body>
</html>